{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T20 Cricket Data Exploration for Linear Regression\n",
    "\n",
    "This notebook explores T20 cricket data to understand patterns and prepare for linear regression modeling.\n",
    "\n",
    "## Objectives\n",
    "1. Load and explore T20/IT20 male cricket data\n",
    "2. Analyze target variable distribution (innings totals)\n",
    "3. Examine feature relationships and correlations\n",
    "4. Assess data quality and completeness\n",
    "5. Generate insights for model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import project modules\n",
    "from cricket.ml.data_preparation import T20DataPreparator, load_cricket_data\n",
    "from cricket.transformation.match import (\n",
    "    get_current_score,\n",
    "    get_wickets_fallen,\n",
    "    get_overs_remaining,\n",
    ")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cricket data\n",
    "DATA_PATH = \"../data/ball_level_data.parquet\"\n",
    "\n",
    "print(f\"Loading data from: {DATA_PATH}\")\n",
    "raw_data = load_cricket_data(DATA_PATH)\n",
    "\n",
    "print(f\"\\nDataset shape: {raw_data.shape}\")\n",
    "print(f\"Columns: {raw_data.columns}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data summary\n",
    "print(\"Data Summary:\")\n",
    "print(f\"Total matches: {raw_data.select('match_id').n_unique()}\")\n",
    "print(f\"Total balls: {len(raw_data)}\")\n",
    "print(\n",
    "    f\"Date range: {raw_data.select('match_id').min().item()} to {raw_data.select('match_id').max().item()}\"\n",
    ")\n",
    "\n",
    "# Match format distribution\n",
    "print(\"\\nMatch format distribution:\")\n",
    "format_counts = (\n",
    "    raw_data.group_by(\"match_type\")\n",
    "    .agg(pl.col(\"match_id\").n_unique().alias(\"matches\"))\n",
    "    .sort(\"matches\", descending=True)\n",
    ")\n",
    "print(format_counts)\n",
    "\n",
    "# Gender distribution\n",
    "print(\"\\nGender distribution:\")\n",
    "gender_counts = (\n",
    "    raw_data.group_by(\"gender\")\n",
    "    .agg(pl.col(\"match_id\").n_unique().alias(\"matches\"))\n",
    "    .sort(\"matches\", descending=True)\n",
    ")\n",
    "print(gender_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. T20 Data Filtering and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data preparator and filter T20 data\n",
    "preparator = T20DataPreparator(sample_overs=[5.0, 10.0, 15.0])\n",
    "\n",
    "# Filter for T20/IT20 male matches\n",
    "t20_data = preparator.filter_t20_matches(raw_data)\n",
    "\n",
    "print(\"After T20/male filtering:\")\n",
    "print(f\"Matches: {t20_data.select('match_id').n_unique()}\")\n",
    "print(f\"Balls: {len(t20_data)}\")\n",
    "print(f\"Reduction: {(1 - len(t20_data) / len(raw_data)) * 100:.1f}%\")\n",
    "\n",
    "# Validate data quality\n",
    "quality_summary = preparator.validate_data_quality(t20_data)\n",
    "print(\"\\nData Quality Summary:\")\n",
    "for key, value in quality_summary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Add Match State Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add match state features\n",
    "print(\"Adding match state features...\")\n",
    "\n",
    "# Add current score\n",
    "t20_data = get_current_score(t20_data)\n",
    "print(\"✓ Added current_score\")\n",
    "\n",
    "# Add wickets fallen\n",
    "t20_data = get_wickets_fallen(t20_data)\n",
    "print(\"✓ Added wickets_fallen\")\n",
    "\n",
    "# Add overs remaining\n",
    "t20_data = get_overs_remaining(t20_data)\n",
    "print(\"✓ Added overs_remaining\")\n",
    "\n",
    "print(f\"\\nDataset now has {len(t20_data.columns)} columns\")\n",
    "print(\"New feature columns: current_score, wickets_fallen, overs_remaining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature distributions\n",
    "feature_cols = [\"current_score\", \"wickets_fallen\", \"overs_remaining\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, col in enumerate(feature_cols):\n",
    "    data_pd = t20_data.select(col).to_pandas()[col]\n",
    "    axes[i].hist(data_pd, bins=50, alpha=0.7, edgecolor=\"black\")\n",
    "    axes[i].set_title(f\"Distribution of {col}\")\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics for features\n",
    "print(\"\\nFeature Summary Statistics:\")\n",
    "feature_stats = t20_data.select(feature_cols).describe()\n",
    "print(feature_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create innings-level target variable\n",
    "target_df = preparator.create_target_variable(t20_data)\n",
    "\n",
    "print(f\"Created {len(target_df)} innings targets\")\n",
    "print(\"Target variable statistics:\")\n",
    "print(target_df.select(\"total_runs_innings\").describe())\n",
    "\n",
    "# Plot target variable distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Histogram\n",
    "runs_data = target_df.select(\"total_runs_innings\").to_pandas()[\"total_runs_innings\"]\n",
    "ax1.hist(runs_data, bins=30, alpha=0.7, edgecolor=\"black\")\n",
    "ax1.axvline(\n",
    "    runs_data.mean(), color=\"red\", linestyle=\"--\", label=f\"Mean: {runs_data.mean():.1f}\"\n",
    ")\n",
    "ax1.axvline(\n",
    "    runs_data.median(),\n",
    "    color=\"orange\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Median: {runs_data.median():.1f}\",\n",
    ")\n",
    "ax1.set_title(\"Distribution of T20 Innings Totals\")\n",
    "ax1.set_xlabel(\"Total Runs\")\n",
    "ax1.set_ylabel(\"Frequency\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "ax2.boxplot(runs_data)\n",
    "ax2.set_title(\"Box Plot of T20 Innings Totals\")\n",
    "ax2.set_ylabel(\"Total Runs\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional target analysis\n",
    "print(\"\\nTarget Variable Analysis:\")\n",
    "print(f\"Range: {runs_data.min():.0f} - {runs_data.max():.0f} runs\")\n",
    "print(f\"Std Dev: {runs_data.std():.1f} runs\")\n",
    "print(\"\\nPercentiles:\")\n",
    "for p in [10, 25, 50, 75, 90, 95]:\n",
    "    print(f\"  {p}th: {np.percentile(runs_data, p):.0f} runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Sampling and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample features at specified over marks\n",
    "feature_samples = preparator.sample_features_at_overs(t20_data)\n",
    "\n",
    "print(f\"Created {len(feature_samples)} feature samples\")\n",
    "print(f\"Sample points: {preparator.sample_overs}\")\n",
    "\n",
    "# Examine sample distribution across overs\n",
    "sample_counts = (\n",
    "    feature_samples.group_by(\"sample_over\")\n",
    "    .agg(pl.count().alias(\"samples\"))\n",
    "    .sort(\"sample_over\")\n",
    ")\n",
    "print(\"\\nSamples per over mark:\")\n",
    "print(sample_counts)\n",
    "\n",
    "# Join with target variable for analysis\n",
    "joined_data = feature_samples.join(\n",
    "    target_df.select([\"match_id\", \"innings_number\", \"total_runs_innings\"]),\n",
    "    on=[\"match_id\", \"innings_number\"],\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "print(f\"\\nJoined data shape: {joined_data.shape}\")\n",
    "print(f\"Features available for modeling: {len(joined_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze features by over mark\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Convert to pandas for easier plotting\n",
    "joined_pd = joined_data.to_pandas()\n",
    "\n",
    "feature_cols = [\"current_score\", \"wickets_fallen\", \"overs_remaining\"]\n",
    "\n",
    "for i, col in enumerate(feature_cols):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # Box plot by over mark\n",
    "    sns.boxplot(data=joined_pd, x=\"sample_over\", y=col, ax=ax)\n",
    "    ax.set_title(f\"{col} by Over Mark\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Target vs current score colored by over mark\n",
    "ax = axes[3]\n",
    "for over in preparator.sample_overs:\n",
    "    over_data = joined_pd[joined_pd[\"sample_over\"] == over]\n",
    "    ax.scatter(\n",
    "        over_data[\"current_score\"],\n",
    "        over_data[\"total_runs_innings\"],\n",
    "        label=f\"After {over} overs\",\n",
    "        alpha=0.6,\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(\"Current Score\")\n",
    "ax.set_ylabel(\"Final Total\")\n",
    "ax.set_title(\"Current Score vs Final Total by Over Mark\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "analysis_cols = [\n",
    "    \"current_score\",\n",
    "    \"wickets_fallen\",\n",
    "    \"overs_remaining\",\n",
    "    \"total_runs_innings\",\n",
    "]\n",
    "corr_data = joined_pd[analysis_cols]\n",
    "\n",
    "correlation_matrix = corr_data.corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    cmap=\"RdBu_r\",\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_title(\"Feature Correlation Matrix\", fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Correlation with Target Variable (total_runs_innings):\")\n",
    "target_corr = correlation_matrix[\"total_runs_innings\"].sort_values(ascending=False)\n",
    "for feature, corr in target_corr.items():\n",
    "    if feature != \"total_runs_innings\":\n",
    "        print(f\"  {feature:15}: {corr:6.3f}\")\n",
    "\n",
    "print(\"\\nFeature Inter-correlations:\")\n",
    "feature_cols = [\"current_score\", \"wickets_fallen\", \"overs_remaining\"]\n",
    "for i, col1 in enumerate(feature_cols):\n",
    "    for col2 in feature_cols[i + 1 :]:\n",
    "        corr = correlation_matrix.loc[col1, col2]\n",
    "        print(f\"  {col1} vs {col2}: {corr:6.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Scatter Plot Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot matrix\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "plot_cols = [\"current_score\", \"wickets_fallen\", \"overs_remaining\"]\n",
    "\n",
    "for i, col1 in enumerate(plot_cols):\n",
    "    for j, col2 in enumerate(plot_cols):\n",
    "        ax = axes[i, j]\n",
    "\n",
    "        if i == j:\n",
    "            # Diagonal: histogram\n",
    "            ax.hist(joined_pd[col1], bins=30, alpha=0.7, edgecolor=\"black\")\n",
    "            ax.set_title(f\"Distribution of {col1}\")\n",
    "        else:\n",
    "            # Off-diagonal: scatter plot\n",
    "            ax.scatter(joined_pd[col2], joined_pd[col1], alpha=0.5)\n",
    "            ax.set_xlabel(col2)\n",
    "            ax.set_ylabel(col1)\n",
    "\n",
    "            # Add correlation coefficient\n",
    "            corr = joined_pd[col1].corr(joined_pd[col2])\n",
    "            ax.text(\n",
    "                0.05,\n",
    "                0.95,\n",
    "                f\"r = {corr:.3f}\",\n",
    "                transform=ax.transAxes,\n",
    "                bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.8),\n",
    "            )\n",
    "\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Target vs Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot target vs each feature\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i, feature in enumerate([\"current_score\", \"wickets_fallen\", \"overs_remaining\"]):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # Scatter plot\n",
    "    ax.scatter(joined_pd[feature], joined_pd[\"total_runs_innings\"], alpha=0.5)\n",
    "\n",
    "    # Add trend line\n",
    "    z = np.polyfit(joined_pd[feature], joined_pd[\"total_runs_innings\"], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax.plot(\n",
    "        sorted(joined_pd[feature]),\n",
    "        p(sorted(joined_pd[feature])),\n",
    "        \"r--\",\n",
    "        alpha=0.8,\n",
    "        linewidth=2,\n",
    "    )\n",
    "\n",
    "    # Correlation coefficient\n",
    "    corr = joined_pd[feature].corr(joined_pd[\"total_runs_innings\"])\n",
    "    ax.text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        f\"r = {corr:.3f}\",\n",
    "        transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"lightblue\", alpha=0.8),\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(feature, fontsize=12)\n",
    "    ax.set_ylabel(\"Total Runs (Target)\", fontsize=12)\n",
    "    ax.set_title(f\"Target vs {feature}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values Analysis:\")\n",
    "missing_analysis = joined_data.null_count()\n",
    "print(missing_analysis)\n",
    "\n",
    "# Check for outliers using IQR method\n",
    "print(\"\\nOutlier Analysis:\")\n",
    "outlier_cols = [\n",
    "    \"current_score\",\n",
    "    \"wickets_fallen\",\n",
    "    \"overs_remaining\",\n",
    "    \"total_runs_innings\",\n",
    "]\n",
    "\n",
    "for col in outlier_cols:\n",
    "    data_series = joined_pd[col]\n",
    "    Q1 = data_series.quantile(0.25)\n",
    "    Q3 = data_series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = data_series[(data_series < lower_bound) | (data_series > upper_bound)]\n",
    "    outlier_pct = len(outliers) / len(data_series) * 100\n",
    "\n",
    "    print(f\"  {col:20}: {len(outliers):4d} outliers ({outlier_pct:4.1f}%)\")\n",
    "    if len(outliers) > 0:\n",
    "        print(\n",
    "            f\"                       Range: {data_series.min():.1f} - {data_series.max():.1f}\"\n",
    "        )\n",
    "        print(f\"                       Bounds: {lower_bound:.1f} - {upper_bound:.1f}\")\n",
    "\n",
    "# Data completeness by over mark\n",
    "print(\"\\nData Completeness by Over Mark:\")\n",
    "completeness = (\n",
    "    joined_data.group_by(\"sample_over\")\n",
    "    .agg(\n",
    "        [\n",
    "            pl.count().alias(\"total_samples\"),\n",
    "            pl.col(\"current_score\").is_not_null().sum().alias(\"current_score_complete\"),\n",
    "            pl.col(\"wickets_fallen\")\n",
    "            .is_not_null()\n",
    "            .sum()\n",
    "            .alias(\"wickets_fallen_complete\"),\n",
    "            pl.col(\"overs_remaining\")\n",
    "            .is_not_null()\n",
    "            .sum()\n",
    "            .alias(\"overs_remaining_complete\"),\n",
    "        ]\n",
    "    )\n",
    "    .sort(\"sample_over\")\n",
    ")\n",
    "\n",
    "print(completeness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Insights and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate insights\n",
    "print(\"=\" * 60)\n",
    "print(\"T20 LINEAR REGRESSION - DATA EXPLORATION INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Dataset summary\n",
    "print(\"\\n📊 DATASET SUMMARY:\")\n",
    "print(f\"   • Total T20/IT20 matches: {target_df.select('match_id').n_unique()}\")\n",
    "print(f\"   • Total innings analyzed: {len(target_df)}\")\n",
    "print(f\"   • Feature samples for modeling: {len(joined_data)}\")\n",
    "print(f\"   • Sample points: {preparator.sample_overs} overs\")\n",
    "\n",
    "# Target variable insights\n",
    "print(\"\\n🎯 TARGET VARIABLE (Total Runs):\")\n",
    "print(f\"   • Mean: {runs_data.mean():.1f} runs\")\n",
    "print(f\"   • Range: {runs_data.min():.0f} - {runs_data.max():.0f} runs\")\n",
    "print(f\"   • Standard deviation: {runs_data.std():.1f} runs\")\n",
    "print(\n",
    "    f\"   • Typical range (25th-75th): {runs_data.quantile(0.25):.0f} - {runs_data.quantile(0.75):.0f} runs\"\n",
    ")\n",
    "\n",
    "# Feature correlation insights\n",
    "print(\"\\n🔗 FEATURE CORRELATIONS WITH TARGET:\")\n",
    "target_corrs = (\n",
    "    correlation_matrix[\"total_runs_innings\"]\n",
    "    .drop(\"total_runs_innings\")\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "for feature, corr in target_corrs.items():\n",
    "    strength = (\n",
    "        \"Strong\" if abs(corr) > 0.7 else \"Moderate\" if abs(corr) > 0.4 else \"Weak\"\n",
    "    )\n",
    "    direction = \"positive\" if corr > 0 else \"negative\"\n",
    "    print(f\"   • {feature}: {corr:.3f} ({strength} {direction})\")\n",
    "\n",
    "# Model readiness assessment\n",
    "print(\"\\n✅ MODEL READINESS ASSESSMENT:\")\n",
    "\n",
    "# Check linear relationships\n",
    "strong_corrs = [f for f, c in target_corrs.items() if abs(c) > 0.5]\n",
    "if strong_corrs:\n",
    "    print(f\"   ✓ Strong linear relationships found: {', '.join(strong_corrs)}\")\n",
    "else:\n",
    "    print(\"   ⚠ No strong linear relationships (may affect model performance)\")\n",
    "\n",
    "# Check multicollinearity\n",
    "feature_corrs = []\n",
    "for i, col1 in enumerate(feature_cols):\n",
    "    for col2 in feature_cols[i + 1 :]:\n",
    "        corr = correlation_matrix.loc[col1, col2]\n",
    "        feature_corrs.append(abs(corr))\n",
    "\n",
    "max_feature_corr = max(feature_corrs)\n",
    "if max_feature_corr < 0.7:\n",
    "    print(\n",
    "        f\"   ✓ Low multicollinearity (max inter-feature correlation: {max_feature_corr:.3f})\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        f\"   ⚠ Potential multicollinearity concern (max correlation: {max_feature_corr:.3f})\"\n",
    "    )\n",
    "\n",
    "# Check data quality\n",
    "total_nulls = joined_data.null_count().sum_horizontal().sum()\n",
    "if total_nulls == 0:\n",
    "    print(\"   ✓ No missing values in modeling dataset\")\n",
    "else:\n",
    "    print(f\"   ⚠ {total_nulls} missing values need handling\")\n",
    "\n",
    "print(\"\\n🚀 RECOMMENDATIONS:\")\n",
    "print(\"   • Proceed with linear regression modeling\")\n",
    "print(\"   • Consider feature scaling (StandardScaler recommended)\")\n",
    "print(\"   • Monitor for overfitting given dataset size\")\n",
    "print(\"   • Validate model assumptions (linearity, homoscedasticity)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Exploration complete! Ready for model training.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Based on this exploration:\n",
    "\n",
    "1. **Data Quality**: ✅ Good data quality with minimal missing values\n",
    "2. **Linear Relationships**: Found meaningful correlations between features and target\n",
    "3. **Feature Engineering**: Current features are suitable for linear regression\n",
    "4. **Model Development**: Ready to proceed with training pipeline\n",
    "\n",
    "**Next notebook**: `t20_model_training.ipynb` for model development and training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}